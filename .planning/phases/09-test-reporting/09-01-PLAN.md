---
phase: "09-test-reporting"
plan: "01"
type: "execute"
wave: 1
depends_on: []
files_modified:
  - "src/validate_profile/reporter.py"
  - "src/validate_profile/cli.py"
autonomous: true
user_setup: []
must_haves:
  truths:
    - "Script generates summary of all profiles tested with pass/fail status"
    - "Script reports profiles with validation failures and specific reasons"
    - "Script reports pass/fail counts for all validation types"
    - "Script exits with non-zero code if any profiles fail validation"
  artifacts:
    - path: "src/validate_profile/reporter.py"
      provides: "Validation report generation"
      exports: "generate_report()"
    - path: "src/validate_profile/cli.py"
      provides: "CLI interface for validation reporting"
      exports: "main()"
  key_links:
    - from: "src/validate_profile/cli.py"
      to: "src/validate_profile/core.py"
      via: "import validation results"
      pattern: "from.*core.*import"
---

<objective>
Create comprehensive validation report generation for Phase 9 of the Espresso Profile Translator.

Purpose: Users get actionable feedback on translation quality across all profiles in a single command.

Output: Working validation reporting system that generates summaries, failure details, pass/fail counts, and proper exit codes.
</objective>

<execution_context>
@/home/juan/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/juan/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md

# Prior phase summaries for validation pattern understanding
@/home/juan/Repos/Meticulous-to-Gaggimate-profile-adapter/.planning/phases/07-extraction-objective-validation/07-SUMMARY.md
@/home/juan/Repos/Meticulous-to-Gaggimate-profile-adapter/.planning/phases/08-extraction-type-validation/08-SUMMARY.md

# Existing validation code patterns
@/home/juan/Repos/Meticulous-to-Gaggimate-profile-adapter/src/validate_profile/reporter.py
@/home/juan/Repos/Meticulous-to-Gaggimate-profile-adapter/src/validate_profile/cli.py
@/home/juan/Repos/Meticulous-to-Gaggimate-profile-adapter/src/validate_profile/core.py
</context>

<tasks>

<task type="auto">
  <name>Extend reporter.py with comprehensive report generation</name>
  <files>src/validate_profile/reporter.py</files>
  <action>
    Extend the existing reporter.py module to support comprehensive validation reporting.

    ADD to reporter.py:
    
    1. **Profile-level result tracking** - Create dataclass to track each profile's validation status:
       ```python
       @dataclass
       class ProfileResult:
           name: str
           source_file: str
           translated_file: str
           passed: bool
           objective_failures: List[str] = field(default_factory=list)
           type_failures: List[str] = field(default_factory=list)
           error_message: Optional[str] = None
       ```

    2. **Report generation function** - Add function to generate comprehensive report:
       ```python
       def generate_report(
           results: List[ProfileResult],
           output_format: str = "text"
       ) -> str:
           """Generate comprehensive validation report."""
       ```

    3. **Summary section** - Include:
       - Total profiles tested
       - Pass/fail counts (objective, type, overall)
       - Pass rate percentage

    4. **Failure details section** - For each failed profile:
       - Profile name
       - Specific failure reasons (objective and type)
       - Error message if translation failed

    5. **Format support** - Support text and JSON output formats

    Reference existing reporter.py patterns for dataclass style and output formatting.
  </action>
  <verify>
    python -c "from src.validate_profile.reporter import generate_report, ProfileResult; print('Reporter imports OK')"
  </verify>
  <done_report() function>
    generate exists and accepts ProfileResult list, returns formatted report string
  </done>
</task>

<task type="auto">
  <name>Update cli.py to integrate validation reporting</name>
  <files>src/validate_profile/cli.py</files>
  <action>
    Update the CLI to support comprehensive validation and reporting.

    MODIFY cli.py to:

    1. **Add report generation flag** - Accept --report flag to generate comprehensive output:
       ```python
       parser.add_argument(
           '--report',
           action='store_true',
           help='Generate comprehensive validation report'
       )
       ```

    2. **Add output format option** - Accept --format text|json:
       ```python
       parser.add_argument(
           '--format',
           choices=['text', 'json'],
           default='text',
           help='Report output format'
       )
       ```

    3. **Add summary-only flag** - Accept --summary for abbreviated output:
       ```python
       parser.add_argument(
           '--summary',
           action='store_true',
           help='Show only pass/fail summary'
       )
       ```

    4. **Integrate validation phases** - In main(), run both objective and type validation:
       ```python
       # Run objective validation
       objective_results = validate_objectives(source, translated, tolerance)
       
       # Run type validation  
       type_results = validate_types(source, translated)
       
       # Collect profile results
       profile_results = build_profile_results(source, translated, objective_results, type_results)
       ```

    5. **Generate and print report** - Call reporter.generate_report() with results

    6. **Implement proper exit codes**:
       - Exit 0 if all profiles pass validation
       - Exit 1 if any profiles fail validation
       - Exit 2 for other errors (file not found, etc.)

    Reference existing cli.py structure for argument parsing and error handling patterns.
  </action>
  <verify>
    python -c "from src.validate_profile.cli import main, parse_args; print('CLI imports OK')" && python -m src.validate_profile.cli --help 2>&1 | grep -E "(report|format|summary)" || echo "Arguments need verification"
  </verify>
  <done>
    CLI accepts --report, --format, and --summary flags; exits with proper codes based on validation results
  </done>
</task>

</tasks>

<verification>
# Integration verification
1. Test reporter.py imports and basic functionality:
   python -c "
   from src.validate_profile.reporter import generate_report, ProfileResult
   results = [ProfileResult(name='test.json', source='test.json', translated='test.json', passed=True)]
   report = generate_report(results)
   print(report)
   "

2. Test CLI with --report flag:
   python -m src.validate_profile.cli --report --help
   
3. Test with actual profiles:
   python -m src.validate_profile.cli --report
</verification>

<success_criteria>
- [x] REPORT-01: generate_report() produces summary of all profiles tested
- [x] REPORT-02: Report includes profiles with failures and specific reasons
- [x] REPORT-03: Pass/fail counts displayed for each validation type
- [x] REPORT-04: Script exits non-zero if any profiles fail
- [x] All existing tests pass (validate-objective and validate-type functionality preserved)
</success_criteria>

<output>
After completion, create `.planning/phases/09-test-reporting/09-01-SUMMARY.md` with:
- Validation results from reporter.py and CLI integration
- Examples of report output format
- Exit code behavior documented
</output>
